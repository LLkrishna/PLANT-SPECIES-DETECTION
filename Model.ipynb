{"cells":[{"cell_type":"markdown","source":["**Importing the necessary modules**\n"],"metadata":{"id":"X5Q5jffkgoP4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVz_nJ6Ldnm-"},"outputs":[],"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["**Connecting to the Drive**"],"metadata":{"id":"PybME0R6g2gV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeGe6jsed7Y3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","IMAGE_SIZE = [224, 224]"]},{"cell_type":"markdown","source":["**Loading the dataset's from the directory**"],"metadata":{"id":"B8nn8MSMhBh3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up_p7v8Qd-VJ"},"outputs":[],"source":["train_directory= '/content/drive/My Drive/Colab Notebooks/plant_1/TRAIN_NEW'\n","test_directory= '/content/drive/My Drive/Colab Notebooks/plant_1/test'\n","val_directory= '/content/drive/My Drive/Colab Notebooks/plant_1/valid'"]},{"cell_type":"markdown","source":["**Freezing Pre-trained VGG16 Model Layers in Keras**"],"metadata":{"id":"OUdG72tHhQ1X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrd0MN69f3sH"},"outputs":[],"source":["vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n","\n","# don't train existing weights\n","for layer in vgg.layers:\n","  layer.trainable = False"]},{"cell_type":"markdown","source":["**Adding Custom Layers to Pre-trained VGG16 Model in Keras**"],"metadata":{"id":"vZlHBXwgiIO3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rb9MneoYgFwH"},"outputs":[],"source":["# our layers - you can add more if you want\n","x = Flatten()(vgg.output)\n","x = Dense(1000, activation='relu')(x)\n","prediction = Dense(len(folders), activation='softmax')(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9Zfz2ZRgJGZ"},"outputs":[],"source":["# create a model object\n","model = Model(inputs=vgg.input, outputs=prediction)\n","# view the structure of the model\n","model.summary()"]},{"cell_type":"markdown","source":["**Compiling the Customized VGG16 Model in Keras.**"],"metadata":{"id":"6D_ZxcUYiajI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWWrI0l7gNt_"},"outputs":[],"source":["model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")"]},{"cell_type":"markdown","source":["**Preparing Image Data Generators for Training and Testing in Keras.**"],"metadata":{"id":"AeEHL74piyYd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMlBriNigS2j"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory(train_directory,\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","\n","test_set = test_datagen.flow_from_directory(test_directory,\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n","\n","print(len(training_set))\n","print(len(test_set))"]},{"cell_type":"markdown","source":["**Training the Customized VGG16 Model on Image Data in Keras.**"],"metadata":{"id":"k4T8J5Wmi-Or"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyuKNc_agh_a"},"outputs":[],"source":["r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=10,\n","  steps_per_epoch=len(training_set),\n","  validation_steps=len(test_set)\n",")"]},{"cell_type":"markdown","source":["**Plotting Training and Validation Losses.**"],"metadata":{"id":"U5SyuaMgjj-o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfktgptJgmKz"},"outputs":[],"source":["# loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["**Plotting Training and Validation Accuracies.**"],"metadata":{"id":"qlGUh6SqjrYn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-U0yJvAagq0E"},"outputs":[],"source":["# accuracies\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["**Saving the Trained Model Weights**"],"metadata":{"id":"yjSABuisjgcW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HGhocntgu3K"},"outputs":[],"source":["model.save('/content/drive/My Drive/Colab Notebooks/plant_1/Model_weights.h5')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}